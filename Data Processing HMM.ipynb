{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize, wordpunct_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespeare.txt', 'r') as f:\n",
    "    data = f.read().lower() #Reading in Sonnets in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = data.split('\\n\\n')\n",
    "#Splitting each sonnet up based on double gap between poems\n",
    "sonnets = [sonnet.strip() for sonnet in sonnets] #Removing whitespace\n",
    "sonnets.pop(98) #Removing Sonnets with not 14 lines\n",
    "sonnets.pop(124)\n",
    "lines = [sonnet.split('\\n') for sonnet in sonnets] #splitting up the sonnets into lines\n",
    "lines = [line[1:] for line in lines] #Removing index of poem\n",
    "quattrains = [line[0:4] for line in lines] + [line[4:8] for line in lines] + [line[8:12] for line in lines] #splitting data\n",
    "couplets = [line[12:15] for line in lines]                                  #into quattrains and couplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "#tokenizing each quattrain and coup line by line, not excluding bigrams/splitting hyphenated words\n",
    "token_quat = [ [tknzr.tokenize(line) for line in quattrain] for quattrain in quattrains] \n",
    "token_coup = [ [tknzr.tokenize(line) for line in couplet] for couplet in couplets]\n",
    "\n",
    "\n",
    "punct = set(['.', ',', '!', ':', ';'])\n",
    "\n",
    "filtered_token_quat = [ [[word for word in line if word not in punct] for line in quattrain] for quattrain in token_quat]\n",
    "concat_token_quat = [quattrain[0] + quattrain[1] + quattrain[2] + quattrain[3] for quattrain in filtered_token_quat]\n",
    "\n",
    "filtered_token_coup = [ [[word for word in line if word not in punct] for line in couplet] for couplet in token_coup]\n",
    "concat_token_coup = [couplet[0] + couplet[1] for couplet in filtered_token_coup]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
